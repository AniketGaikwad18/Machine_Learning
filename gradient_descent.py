# -*- coding: utf-8 -*-
"""Gradient_Descent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vMVFKcZ-Kg_k119KjDDsyYsv6WzXIL8m
"""

from sklearn.datasets import make_regression

import numpy as np

X,y = make_regression(n_samples=100,n_features=1,n_informative=1,noise=10,random_state=13)

import matplotlib.pyplot as plt
plt.scatter(X,y)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)

from sklearn.linear_model import LinearRegression

reg = LinearRegression()
reg.fit(X_train,y_train)

reg.coef_

reg.intercept_

y_pred = reg.predict(X_test)
from sklearn.metrics import r2_score
r2_score(y_test,y_pred)

lr = LinearRegression()

from sklearn.model_selection import cross_val_score

np.mean(cross_val_score(lr,X,y,scoring='r2',cv=10))

class GDRegressor:

  def __init__(self,learning_rate,epochs):
    self.n = 100
    self.b = -120
    self.lr = learning_rate
    self.epochs = epochs

  def fit(self,X,y):
    for i in range(self.epochs):
      loss_slope_b = -2 * np.sum(y - self.n*X.ravel()-self.b)
      loss_slope_n = -2 * np.sum((y - self.n*X.ravel()-self.b)*X.ravel())
      self.b = self.b - (self.lr * loss_slope_b)
      self.n = self.n - (self.lr * loss_slope_n)
    print(self.n,self.b)

  def predict(self,X):
    return self.n * X + self.b

gd = GDRegressor(0.001,50)

gd.fit(X_train,y_train)

y_pred = gd.predict(X_test)
from sklearn.metrics import r2_score
r2_score(y_test,y_pred)